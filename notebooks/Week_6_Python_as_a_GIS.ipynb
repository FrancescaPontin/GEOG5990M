{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOG5990M Programming for Geographical Information Analysis <a class=\"tocSkip\">\n",
    "\n",
    "#### Contact: F.L.Pontin@leeds.ac.uk <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is coding custom we import the required packages at the beginning<br>\n",
    "<font color='orchid'> <b>Import the packages below </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Google Collab users uncomment and run these lines of code\n",
    "# !pip install contextily\n",
    "# !pip install geoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "import contextily as ctx\n",
    "import seaborn as sns\n",
    "\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imported a new package 'geopandas'. Geopandas works like pandas but also handles spatial data. Geopandas was designed to allow people to easily handle and use spatial datasets in Python. <br>\n",
    "\n",
    "Geopandas has some datasets built into the package. We are going to use these datasets to get started and make some maps.\n",
    "\n",
    "<font color='orchid'> <b>Run the code below to explore which datasets are built in to the geopandas package </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.datasets.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas has three in built datasets. We are going to use 'naturalearth_cities' and 'naturalearth_lowres'. <br>\n",
    "To use the datasets we need to read them in from where they are stored in the geopandas package file directory. <br>\n",
    "We will use the print function to check we have got the correct file path.<br>\n",
    "<font color= 'orchid'> <b>Run the code bellow to get the file paths for the datasets </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_path = gpd.datasets.get_path('naturalearth_cities')\n",
    "countries_path = gpd.datasets.get_path('naturalearth_lowres')\n",
    "print(cities_path)\n",
    "print(countries_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapefiles\n",
    "Notice the file type of the 'naturalearth_cities' and 'naturalearth_lowres' is \".shp\". This is a shapefile [\"A shapefile is an Esri vector data storage format for storing the location, shape, and attributes of geographic features. It is stored as a set of related files and contains one feature class.\"](https://doc.arcgis.com/en/arcgis-online/reference/shapefiles.htm).\n",
    "\n",
    "## Reading in spatial data\n",
    "We need to read these shp files in, geopandas work the same way as pandas, but are also able to handle the spatial element of the dataset. Therefore the code we use is very similar. We use <code>geopandas.read_file(<font color =red>file_path</font>) </code> replacing <font color =red>\"file_path\"</font>, with the actual path to the shapefile you want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> This is very similar to the <code>pd.read_csv() function</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orchid'> Run the code below to read the spatial data in </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the shape file data\n",
    "cities = gpd.read_file(cities_path)\n",
    "countries = gpd.read_file(countries_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Just as we have done before we are goign to explore the data by having a look at the dataframes and by visualising both the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the cities geopandas dataframe \n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataframe has two columns:\n",
    "- 'name' naming the city\n",
    "- 'geometry' listing the type of geometry, in this case POINT. And two numbers - the coordiantes of the point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple spatial data visualisation\n",
    "### Point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cities data\n",
    "\n",
    "# define the plot size and nummber of subplots (1 i.e. 1 plot)\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "# plot the  cities, specifying the subplot axis\n",
    "cities.plot(ax=ax)\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same for the countries dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the countries dataframe\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b> the geometry column this time is made up of POLYGON data, made up of many coordiante points. <br>\n",
    "Let us have a closer look at the polygon geometry. We are going to look at the geometry of row 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at index 3 (for me it is Canada) of the geometry column\n",
    "# Notice the shape is quite complex with lots of edges\n",
    "countries.loc[3,'geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us look at the list of coordiantes\n",
    "print(countries.loc[3,'geometry'])\n",
    "# Each point is a corner of the country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot all the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16, 8))\n",
    "countries.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geopandas.explore()\n",
    "\n",
    "<code>gpd.explore()</code> is a really useful function that generate an interactive leaflet map based on GeoDataFrame. It is particulalry useful for inital data exploration. the function creates:\n",
    "- a navigatable map\n",
    "- with 'zoom in and out' functionality\n",
    "- and hover over function displaying the variables in the GeoDataFrame\n",
    "\n",
    "The <code>.explore()</code> has many customisabel parameters, see the [package documentation](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Reference Systems (CRS)\n",
    "Before we map multiple layers we need to check they have the same Coordinate Reference System (CRS). Using the <code>.crs</code> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at what happens when we change the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAD83 Canadian Spatial Reference System: Large and medium scale topographic mapping and engineering survey.\n",
    "countries_new_proj= countries.to_crs(epsg=2953)\n",
    "\n",
    "# EPSG:3851 New Zealand Geodetic Datum 2000: Spatial referencing and conformal mapping on the NZ continental shelf.\n",
    "countries_new_proj2= countries.to_crs(epsg=3851)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two diifferent projections\n",
    "f, ax = plt.subplots(1,3, figsize=(30, 20))\n",
    "countries.plot(ax=ax[0])\n",
    "countries_new_proj.plot(ax=ax[1])\n",
    "countries_new_proj2.plot(ax=ax[2])\n",
    "plt.show()\n",
    "# Note the different scales on the axis and orrientation of the countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layering maps\n",
    "Much like other mapping software it is possible to layer maps in Python. We will plot the cities on top of the countires dataset.\n",
    "\n",
    "We need to check the CRS of both datasets is the same so we can accurately plot the layers on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the CRS are the same\n",
    "print(cities.crs, countries.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the cities and countries together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "# define the basemap plot it on the sublot axis\n",
    "base = countries.plot(ax=ax)\n",
    "\n",
    "# plot the cities on the basemap axis, colour the cities red\n",
    "cities.plot(ax=base,color='red')\n",
    "\n",
    "# show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth Mapping\n",
    "Choropleth maps are maps where the polygons are coloured differenet shades or colours based on a value. E.g. Populaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plot size\n",
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "# Plot the countries, specifying to plot the population estimate column \n",
    "# Add legend (legend =True)\n",
    "countries.plot(ax=ax, column ='pop_est', legend=True)\n",
    "# show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'orchid'> <b>Code your own choropleth map for 'gdp_mp_est'<b></font><br>\n",
    "    Answer at the end of the workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code your choropleth map here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Categorical variables\n",
    "It is possible to create choropleth maps with categorical variables. To do this we specify <code> categorical=True,</code> withn the <code>plot()</code> function.<br> If we treat the continent of the country as a categorical variable we can colour the countries based on the continent they are in.<br>\n",
    "\n",
    "Note the legend of the map is now separate colours and not a continuous colour bar \n",
    "\n",
    "<font color ='orchid'> <b> Run the code below to plot a categorical chloropleth </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "countries.plot(ax=ax, column ='continent', categorical=True, legend=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting spatial data\n",
    "We can also work with and plot just a subset of the spatial data. For example we might only be interested in Africa. In which case we can use the <code>.loc[]</code> fucntion to locate all rows (countries) where the continent is Africe. Just like we would normally do in a non-spatial pandas dataframe.<br>\n",
    "\n",
    "<font color ='orchid'> <b>Run the code below </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locate countries (rows) in Africa\n",
    "africa= countries.loc[countries['continent']=='Africa']\n",
    "# view the newly created Africa dataframe\n",
    "africa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now possible to plot just Africa. We can also put maps side by side to compare them. Here we are going to plot population estimate for each country and the estimated GDP for each country.<br>\n",
    "\n",
    "<font color = 'orchid'> <b> Run the code below,</b> make sure you understand what each line does (there is a lot going on)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with two subplots (maps) \n",
    "f,ax = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "# plot population estimate in subplot 1\n",
    "africa.plot(ax=ax[0], column ='pop_est', legend=True)\n",
    "\n",
    "# plot gdp estimate in subplot 2\n",
    "africa.plot(ax=ax[1], column ='gdp_md_est', legend=True)\n",
    "\n",
    "# give subplot 1 an informative title\n",
    "ax[0].set_title('Population estimate')\n",
    "\n",
    "# give subplot 2 an informative title\n",
    "ax[1].set_title('GDP estimate')\n",
    "\n",
    "# make axis invisible for subplot 1\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "# make axis invisible for subplot 1\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "# show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplots and axes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note on the subplot and ax indexing. It can be a little tricky getting your head arround the indexing used when creating subplots.\n",
    "To create mulitple subplots you use the code below, specifying firstly the number of rows then the number of columns. <br>\n",
    "<code>.subplots([number of rows], [number of columns])</code>\n",
    "\n",
    "When you are then specifyng each individual plot, you need to specify the axes of the plot, using the code <code> ax=ax[]</code>. The indexing for the axes starts at 0. I.e. the first row is 'row 0' and the first column, 'column 0'. This is illustrated below. \n",
    "\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_diagram.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a set of subplots with just one row you only need to specify the column in the <code>ax=ax[]</code> function. <br>\n",
    "I.e. <code>ax=ax[column number]</code> <br>\n",
    "\n",
    "I.e.<code> plt.subplot(1,2) <br>\n",
    "dataframe.plot(ax=ax[0], ... \n",
    "dataframe.plot(ax=ax[1], ... </code>\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_2.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simialrly for a set of subplots with just one column you only need to specify the row in the <code>ax=ax[]</code> function. <br>\n",
    "<code> plt.subplot(2,1) <br>\n",
    "dataframe.plot(ax=ax[0], ... \n",
    "dataframe.plot(ax=ax[1], ... </code>\n",
    "</code>\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_3.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a set of subplots with just multiple rows and columns you only need to specify both in the <code>ax=ax[,]</code> funciton.(row first then column)<br>\n",
    "<code>plt.subplot(2,3)<br>\n",
    "dataframe.plot(ax=ax[0,0], ... \n",
    "dataframe.plot(ax=ax[0,1], ...\n",
    "dataframe.plot(ax=ax[0,2], ...\n",
    "dataframe.plot(ax=ax[1,0], ...\n",
    "dataframe.plot(ax=ax[1,1], ...\n",
    "dataframe.plot(ax=ax[1,2], ...</code>\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_4.png?raw=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "## Extra task: Using USA data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_cities = gpd.read_file(gplt.datasets.get_path('usa_cities'))\n",
    "contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa'))\n",
    "\n",
    "# remove cities in sates not in the contiguous USA (not connected directly to the mainland), for ease of plotting\n",
    "continental_usa_cities = usa_cities.loc[(usa_cities['STATE'] !=\"HI\") & (usa_cities['STATE'] !=\"AK\" ) & (usa_cities['STATE'] !=\"PR\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continental_usa_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continental_usa_cities.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_usa.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "- check the CRS of both geo data frames\n",
    "- produce a layered map of cities and states\n",
    "- Produce a choropleth map of 2010 popualation\n",
    "- produce a choropleth map of elevation\n",
    "- Colour city by state\n",
    "- subset the data to plot a single state e.g. Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Manipulating spatial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Manipulations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffers\n",
    "\n",
    "A buffer in geographic information system (GIS) is a zone around a map feature measured in units of distance or time.\n",
    "\n",
    "In Python we specify the buffer size: the radius of the buffer (in this case size is measured in degrees as the projection is epsg 4326).\n",
    "\n",
    "E.g.:\n",
    "<code> dataframe.crs ={'init': 'epsg:4326'} </code>\n",
    "\n",
    "<code> dataframe.buffer(distance =10) </code> distance = 10 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.buffer(distance=10).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to measure the buffer in meters we can change the projection to [EPSG 3857](https://epsg.io/3857) where the projection unit is meters (rather than degrees). \n",
    "\n",
    "Note: At the world scale this will result in errors in measurement due to the earth curvature. At a smaller scale, depending on where you are mapping other projections are more suitable e.g. [EPSG:4959](https://epsg.io/4959) is used in New Zealand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 500 km (500,0000 m) buffer arround cities\n",
    "\n",
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "cities.to_crs('epsg:3857').buffer(distance=500000).plot(ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to keep information about the area begin buffered in the newly created buffer geo-data-frame it is useful to copy the original data you want to conduct the geometric maipulation on, and name it something else e.g. data_buffer.\n",
    "\n",
    "Then replace the geometry column in the copied data with the calculated buffer geometry.\n",
    "\n",
    "E.g. \n",
    "<code> dataframe_buffer = dataframe.copy() </code>\n",
    "\n",
    "<code> dataframe_buffer['geometry'] = dataframe.buffer(distance)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the cities dataframe\n",
    "cities_buffer = cities.copy()\n",
    "\n",
    "# apply the function (replacing the geometry column with the buffer geometry)\n",
    "cities_buffer['geometry'] = cities.buffer(10)\n",
    "\n",
    "cities_buffer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note because we copied the cities data frame above the cities_buffer data frame contains the name of the city.\n",
    "\n",
    "<font color = 'orchid'> <b> Try just running the code </b> <code>cities.buffer(10, resolution=10)</code>. </font> \n",
    "    \n",
    "Note we get a geopandas array with the geometry data but not the corresponding city that is being buffered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code\n",
    "cities.buffer(10, resolution=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the cities_buffer layer to the map along with the countries and cities layers.\n",
    "\n",
    "<font color = 'orchid'> <b> Run the code below, read the comments to understand what each line of code is doing  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "# define the basemap plot it on the sublot axis\n",
    "base = countries.plot(ax=ax, color='grey')\n",
    "\n",
    "# plot the city buffers on the basemap axis, colour buffers blue\n",
    "cities_buffer.plot(ax=base,color='blue', alpha=0.2)\n",
    "\n",
    "# plot the cities on the basemap axis, colour the cities red\n",
    "cities.plot(ax=base,color='red')\n",
    "\n",
    "# shw the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroids\n",
    "\n",
    "Put simply the centroid is the center most point of a polygon (there are different debated methods of calculating centroids, but unless you are using centroids for a specific purpose the method should not matter too much). \n",
    "\n",
    "#### Why calculate centroids?\n",
    "\n",
    "Lots of geometric manipulations and analysis use centroids. For example you might use centroids to as a proxy to measure the distance between two polygons.\n",
    "\n",
    "\n",
    "<font color = 'orchid'> <b>Use the code </b> <code> dataframe.centroid </code> <b>to find the country centroids (run the next 3 cells of code for the worked example below) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the countries dataframe\n",
    "countries_centroid = countries.copy()\n",
    "\n",
    "# calcualte the centorid \n",
    "# and replace the country geometry (polygon) with the centroid geometry (point)\n",
    "countries_centroid['geometry'] = countries.centroid\n",
    "\n",
    "# check - geometry should contain point data\n",
    "countries_centroid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check it looks as expected\n",
    "countries_centroid.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "# define the basemap plot it on the sublot axis\n",
    "base = countries.plot(ax=ax, color='grey')\n",
    "\n",
    "# plot the country centroids on the basemap axis, colour the centroids purple\n",
    "countries_centroid.plot(ax=base,color='purple')\n",
    "\n",
    "# show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change marker size and colour of plotted points to reflect the data they represent (as we did with the chloropleth maps for polygon data). \n",
    "\n",
    "Note as population sizes are large (i.e. millions) I have assigned marker size to 'pop_est'/1,000,000, so the markers are plot-able. \n",
    "\n",
    "<font color = 'orchid'> <b>Run the code below, then try removing or reducing the size of <code>/1000000</code> and see what happens </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "# define the basemap plot it on the sublot axis\n",
    "base = countries.plot(ax=ax, color='grey')\n",
    "\n",
    "# plot the country centroids on the basemap axis, colour the centroids purple\n",
    "countries_centroid.plot(ax=base,column='pop_est',markersize=countries['pop_est']/1000000, legend=True)\n",
    "\n",
    "# make axis invisible\n",
    "ax.set_axis_off()\n",
    "\n",
    "# show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex hull polygons\n",
    "\n",
    "A convex hull is the smallest polygon that you can draw around a collection of points/a polygon.\n",
    "\n",
    "<font color = 'orchid'> <b>Run the code below to create convex hull polygons (using the code </b><code> dataframe.convex_hull</code><b> around the countries in Africa </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_convex_hull = africa.copy()\n",
    "\n",
    "africa_convex_hull['geometry'] = africa.convex_hull\n",
    "\n",
    "# plot one subplot (1 map), with dimensions 16 X 8\n",
    "f, ax = plt.subplots(1, figsize=(16, 8))\n",
    "\n",
    "# define the basemap plot it on the sublot axis\n",
    "base = africa.plot(ax=ax, color='grey')\n",
    "\n",
    "# plot the africa convex hull polygons\n",
    "# .boundary alows us to just plot the polygon outline\n",
    "africa_convex_hull.boundary.plot(ax=base)\n",
    "\n",
    "# make axis invisible\n",
    "ax.set_axis_off()\n",
    "\n",
    "# show the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Coding task \n",
    "Try: \n",
    "    - Buffering the countries centroids \n",
    "    - Buffering the Africa convex hull polygons \n",
    "    - Getting the centroid of the africa convex hull polygons\n",
    "    - Getting the convex hull polygons of all the countries (note this might look a bit messy)\n",
    "    \n",
    "Answers at end of exercise 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially aggregating data\n",
    "Often our data will not be at the same spatial scale so we may need to aggreaget areas of data together to get them to the same spatial scale. Or we may only be interested in larger spatial trends. Therefore we need to convert our smaller area data to larger area data. In geopandas we can easily so this using the <code>dissolve</code> function. \n",
    "In this example we are going to aggregate countries up to continent level. <br>\n",
    "Think of dissolve as removing all the internal country boarders within the continent to leave just the continent outline.<br>\n",
    "The data for the continent also gets aggregated e.g. estimated populaitn and GDP. <br>\n",
    "<font color='orchid'> <b> Run the code below </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# specify which columns from the countries dataframe we are going to aggreagate,\n",
    "# use the continent column to inform the dissolve\n",
    "continents = countries[['continent', 'pop_est', 'geometry','gdp_md_est']].dissolve(by='continent', aggfunc='mean').reset_index()\n",
    "\n",
    "# view the new continents dataframe\n",
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think carefully about how you want to aggregate the columns, we can also assign an aggfunction to each column (as we did with <code>.agg()</code> in day 1 when looking at the bike share data).\n",
    "\n",
    "E.g.\n",
    "<code>, aggfunc={'r_rank':'mean','r_exp':'max'})</code>\n",
    "\n",
    "There is no quick way to assign multiple columns the same function so with a large dataset you might want to consider which columns you include in the aggregated spatial data frame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_cont = gpd.GeoDataFrame(continents.loc[continents['continent']=='Africa'])\n",
    "africa_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with two subplots (maps) \n",
    "f,ax = plt.subplots(3,1, figsize=(12,20),sharex=True, sharey=True)\n",
    "\n",
    "# plot countries mid year GDP estimate\n",
    "countries.plot(ax=ax[0], column ='gdp_md_est', vmin=0,vmax=countries['gdp_md_est'].max() ,legend=True)\n",
    "\n",
    "# plot countinent average mid year GDP estimate, default legend scale\n",
    "continents.plot(ax=ax[1], column ='gdp_md_est', vmin=0,legend=True)\n",
    "\n",
    "# plot countinent average mid year GDP estimate: countries legend scale \n",
    "continents.plot(ax=ax[2], column ='gdp_md_est', vmin=0,vmax=countries['gdp_md_est'].max() ,legend=True)\n",
    "\n",
    "#patch_col = ax[0].collections[0]\n",
    "#cb = f.colorbar(patch_col, ax=ax, shrink=0.5)\n",
    "\n",
    "# make axis invisible for subplots\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "# give subplot 1 an informative title\n",
    "ax[0].set_title('GDP estimate: countries')\n",
    "\n",
    "# give subplot 2 an informative title\n",
    "ax[1].set_title('GDP estimate: continent average (scale=default)')\n",
    "\n",
    "# give subplot 2 an informative title\n",
    "ax[2].set_title('GDP estimate: continent average (scale=contries scale)')\n",
    "\n",
    "# show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= 'orchid'><b>Run the code below to plot a choropleth map of popualtion estimates for the continents</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "continents.plot(column='pop_est',legend=True, ax=ax)\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orchid'> <b>Try plotting continents by 'gdp_md_est' </font> <br>\n",
    "Answer at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining a non-spatial dataset to a spatial dataset\n",
    "\n",
    "We are going to read in some data about forest coverage of differenet countires and join it to the countires dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='orchid'><b> Run the code below to read in a csv of country forest coverage data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv data using pandas\n",
    "forest = pd.read_csv('../data/week_19/country_forest.csv')\n",
    "# have a quick look at the dataframe\n",
    "forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'country' column in the forest dataframe matches that of the 'name' column in the countries dataframe. As they are formatted in exaclty the same way and each row is unique the country name is a unqiue identifier common to both dataframes. Therefore we will use this column to join our datasets. <br>\n",
    "The code we will use is <code>pd.merge()</code>. We need to specify a few parameteres within the function:<br>\n",
    "\n",
    "- Firstly we specify which dataframes we want to join (in the order we want to join them).<br>\n",
    "<code> pd.merge(countries, forest... </code> <br>\n",
    "\n",
    "\n",
    "- Secondly we need to specify the column in each dataframe, countries is on the left so we specify left_on='name': as we are using the 'name' column from the countires dataframe. And the forest dataframe is on the right so we specify right_on='country' as we are using the 'country' column.<br>\n",
    "<code> pd.merge(countries, forest, left_on='name', right_on='country' ... </code> <br>\n",
    "\n",
    "\n",
    "- Finally we need to specify how the tables are joined. This is based on [SQL join fomats](http://www.complexsql.com/sql-joins-2/). In this case we are using a left join (we keep all the data in the left dataframe and just add the columns form the right dataframe on the end). \n",
    "<code> pd.merge(countries, forest, left_on='name', right_on='country', how='left') </code> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_forest  = pd.merge(countries, forest,  left_on='name', right_on='country', how='left')\n",
    "country_forest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will visualise our newly joined data by plotting the percentage forest in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "country_forest.plot(column='per_forest',legend=True,ax=ax)\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because thereis such a large variaiton in percentage tree cover the above map with a continuous scale doesn't tell us much. To make a more informative plot we can use <code> scheme = ' '</code> \n",
    "And use <code> ['equal_interval', 'quantiles', 'fisher_jenks', 'fisher_jenks_sampled']</code> to define how the choropleth map is scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "country_forest.plot(column='per_forest',legend=True,cmap='Greens',scheme='equal_interval', ax=ax)\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "# position axis\n",
    "ax.get_legend().set_bbox_to_anchor((.12, .4))\n",
    "ax.set_title('Percentage Forest')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orchid'><b> Write your own code to map 'forest_area_km2'</font> <br>\n",
    "Answer at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially Joining Data\n",
    "\n",
    "It is also possible to join data based on their spatial relationship to each other using <code>.sjoin()</code>\n",
    "For example we ight want to know the country each city is in.\n",
    "\n",
    "\n",
    "Like with <code>pd.merge()</code> there are parameters we need to specify when using <code>gpd.sjoin()</code>\n",
    "\n",
    "- Again firstly we specify which dataframes we want to join (in the order we want to join them).<br>\n",
    "<code>gpd.sjoin(cities, countries, ... </code> <br>\n",
    "\n",
    "\n",
    "- Secondly we need to specify how the tables are joined. (Again based on [SQL join fomats](http://www.complexsql.com/sql-joins-2/)). In this case we are using an inner join\n",
    "<code> gpd.sjoin(cities, countries, how=\"inner\",... </code> <br>\n",
    "\n",
    "- Finally we need to specify the tyep of spatial join using 'predicate'. From the [Geopandas documentation](http://geopandas.org/mergingdata.html) <br>\n",
    "<i>The 'predicate' argument specifies how geopandas decides whether or not to join the attributes of one object to another. There are three different join options as follows:\n",
    "    - <b>intersects:</b> The attributes will be joined if the boundary and interior of the object intersect in any way with the boundary and/or interior of the other object.\n",
    "    - <b>within:</b> The attributes will be joined if the object’s boundary and interior intersect only with the interior of the other object (not its boundary or exterior).\n",
    "    - <b>contains:</b> The attributes will be joined if the object’s interior contains the boundary and interior of the other object and their boundaries do not touch at all. </i> <br>\n",
    "    \n",
    "<font color = 'orchid'><b> Run the code below to spatially join the data </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_with_country = gpd.sjoin(cities, countries, how=\"inner\", predicate='intersects')\n",
    "cities_with_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let us plot the cities now coloured by the continent (a column initally from the cities dataframe)\n",
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "\n",
    "# map the countries (basemap)\n",
    "base = continents.plot(ax=ax, cmap='Dark2')\n",
    "# plot the cities and colour them based on continent\n",
    "cities_with_country.plot(column='continent',ax=base, cmap='Spectral')\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try doing the same for US cities and states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay - creating spatial layers from the intersections, unions, and differences between map\n",
    "I have included this for reference with a worked example, to show you how we can look at where spatial data overlaps. Full description an a list of the overlay operations can be found here: https://geopandas.org/set_operations.html\n",
    "Have a read and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_in_buff =gpd.overlay(cities_buffer , countries, how='intersection')\n",
    "countries_in_buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "\n",
    "base = countries.plot(ax=ax,color='grey')\n",
    "countries_in_buff.plot(ax=base, column='name_1',alpha=0.8)\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other interesting maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing geoplot: geospatial data visualization\n",
    "\n",
    "package<i>'Geoplot is a high-level Python geospatial plotting library. It’s an extension to cartopy and matplotlib which makes mapping easy: like seaborn for geospatial. It comes with the following features:'</i>\n",
    "\n",
    "Geoplot has many of the same functions that we have already used in visualising our maps, but also has some additional mapping features. Learn more here: https://residentmario.github.io/geoplot/plot_references/plot_reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel density map\n",
    "\n",
    "Much like the kernel density plots we produced in day 1 this produces a kernel density estimate of spatial point data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1, figsize=(16,8))\n",
    "\n",
    "# map the countries (basemap)\n",
    "base = continents.plot(ax=ax, color='grey')\n",
    "\n",
    "# map the kernel density estimate of world cities\n",
    "gplt.kdeplot(cities, cmap=\"Reds\", shade=True,ax=base, alpha=0.8)\n",
    "\n",
    "# remove axis\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding base maps\n",
    "Base maps provide the reader with context for a map. At a smaller scale than we are currently using the basemap may show road networks or point of interest. \n",
    "\n",
    "We are going to use contextily to add the background map to the geographic data using the <code>.basemap()</code> function. \n",
    "\n",
    "#### Aligning the CRS\n",
    "But first we need to convert the CRS of the data we want to plot to the Web Mercator projection (epsg=3857). So the base maps and geographic data we are plotting align. \n",
    "\n",
    "Unless the data file I want to plot is particularly big I tend to save the data with the Web Mercator projection as a new geodataframe to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_WM.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert CRS to epsg=3857 Web Mercator\n",
    "africa_WM = africa.to_crs(epsg=3857)\n",
    "\n",
    "fig,ax = plt.subplots(1, figsize=(10,10))\n",
    "\n",
    "# plot the africa data as usual \n",
    "africa_WM.plot(column='pop_est',ax=ax,alpha=0.5)\n",
    "\n",
    "# add ctx basemap to ax\n",
    "ctx.add_basemap(ax, crs=africa_WM.crs)\n",
    "\n",
    "#ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different base maps.\n",
    "By default ctx.add_basemap() uses the Stamen Terrain style.\n",
    "\n",
    "To see the available different base maps we can get the provider keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of contextily providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.providers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each will have their own options, accessed by the code: <code> ctx.providers.<text color='red'>provider_from_above</font>.keys()</code>\n",
    "\n",
    "E.g. <code> ctx.providers.OpenStreetMap.keys()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.providers.OpenStreetMap.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the provider and porvider options to choose our base map e.g. <code>OpenStreetMap.Mapnik</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f,ax = plt.subplots(1, figsize=(16,16))\n",
    "\n",
    "# plot the africa data as usual \n",
    "africa_WM .plot(figsize=(10, 10), alpha=0.2,column='pop_est',ax=ax)\n",
    "\n",
    "# add ctx basemap to ax, specifying the basemap provider and options\n",
    "ctx.add_basemap(ax,url=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orchid'><b>  Play around with the providers and options to get different base maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using geoplot to add a basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify basemap (webmap) including projection\n",
    "# using geoplot we specify the figure size in the function\n",
    "ax = gplt.webmap(africa, projection=gcrs.WebMercator(),figsize=(12, 12),)\n",
    "\n",
    "# plot a chlorolpeth of africa by popualtion estiamte\n",
    "gplt.choropleth(africa, ax=ax, hue='pop_est', legend=True, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exercise answers</h1>  <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"tocSkip\">\n",
    "\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/A1.png?raw=true)\n",
    "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/a2.png?raw=true)"
   ]
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRzrJVoMRmOg"
      },
      "source": [
        "# GEOG5990M Programming for Geographical Information Analysis <a class=\"tocSkip\">\n",
        "\n",
        "#### Contact: F.L.Pontin@leeds.ac.uk <a class=\"tocSkip\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0i5aKchRmOi"
      },
      "source": [
        "# Getting started with spatial data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVNQHoUn63zX"
      },
      "source": [
        "Up until now all the packages we have needed have already been installed in the defualt google colab environment. Now we have two further packages that we are going to use: contextily and geoplot, that are not intalled in the defauly environment.\n",
        "\n",
        "To install packages from within a notebook the quickest way is to use: !pip install PACKAGENAME\n",
        "\n",
        "- the ! character is used to execute shell commands directly from a code cell. This allows you to run commands that you would normally run in a terminal or command prompt.\n",
        "- pip is a Python package installer. It's used to install and manage software packages written in Python.\n",
        "- install: a command for pip that tells it to install a package\n",
        "- PACKAGENAME e.g. contextily or geoplot: examples of packages we can install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9RuBAA0RmOj",
        "outputId": "7dcdfb7d-0e99-424b-89aa-5dff34e3ff8a"
      },
      "outputs": [],
      "source": [
        "# #  run these lines of code\n",
        "!pip install contextily\n",
        "!pip install geoplot\n",
        "!pip install git+https://github.com/pmdscully/geo_northarrow.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov8Ch4x7RmOj"
      },
      "source": [
        "As is coding custom we import the required packages at the beginning<br>\n",
        "<font color='orchid'> <b>Import the packages below </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8FVxDlbRmOk"
      },
      "outputs": [],
      "source": [
        "#Import the required packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "import contextily as ctx\n",
        "import seaborn as sns\n",
        "\n",
        "import geoplot as gplt\n",
        "import geoplot.crs as gcrs\n",
        "from geo_northarrow import add_north_arrow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-hH8e6XRmOl"
      },
      "source": [
        "We have imported a new package 'geopandas'. Geopandas works like pandas but also handles spatial data. Geopandas was designed to allow people to easily handle and use spatial datasets in Python. <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEozvY7URmOl"
      },
      "source": [
        "## Reading in spatial data\n",
        "\n",
        "Geopandas dataframes work the same way as pandas dataframes, but are also able to handle the spatial element of the dataset. Therefore the code we use is very similar. We use <code>geopandas.read_file(<font color =red>file_path</font>) </code> replacing <font color =red>\\\"file_path\\\"</font>, with the actual path to the shape datafile you want to use, in this case .geojson files).\n",
        "\n",
        "We are going to read the files from the GitHub repo. The urls to the data on GitHub are:\n",
        "- https://github.com/FrancescaPontin/GEOG5990M/blob/main/data/week_6_7/eeds_travel_to_work_mode_distance.geojson\n",
        "-https://github.com/FrancescaPontin/GEOG5990M/blob/main/data/week_6_7/West_Yorkshire_bus_stops.geojson\n",
        "\n",
        "Remember, when we are reading in data from GitHub we need to ammend the link from: '/blob/' to: '/raw/refs/heads/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avxrJdjjRmOn"
      },
      "source": [
        "<font color='orchid'> Run the code below to read the spatial data in </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMokYk_3ZT2J"
      },
      "outputs": [],
      "source": [
        "bus_stops =gpd.read_file('https://github.com/FrancescaPontin/GEOG5990M/raw/refs/heads/main/data/week_6_7/West_Yorkshire_bus_stops.geojson')\n",
        "leeds=gpd.read_file('https://github.com/FrancescaPontin/GEOG5990M/raw/refs/heads/main/data/week_6_7/leeds_travel_to_work_mode_distance.geojson')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdNanzPLRmOo"
      },
      "source": [
        "### Data Exploration\n",
        "Just as we have done before we are going to explore the data by having a look at the dataframes and by visualising both the data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EskxPXTYRmOo",
        "outputId": "f7ed4dbd-f227-46df-aff9-bcacc6398a5b"
      },
      "outputs": [],
      "source": [
        "# let's have a look at the bus_stops geopandas dataframe\n",
        "bus_stops.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHzNwzsfRmOo"
      },
      "source": [
        "### West Yorkshire Bus Stops\n",
        "\n",
        "https://datamillnorth.org/dataset/vqxk4/west-yorkshire-bus-stops\n",
        "\n",
        "The data includes:\n",
        "- 'STOPID': a unique ID for each bus stop\n",
        "- 'NAME': the name of each bus stop\n",
        "- 'TOWN': the town in which the bus stop is located\n",
        "- '0730__0930'...'2000_2100': average number of buses per hour during the AM Peak (0730 - 0930) Inter-Peak (1200-1400), PM Peak (1500 - 1830) and evening (2000 - 2100) time periods.\n",
        "- 'X' and 'Y': coordinates\n",
        "- 'Z\": elevation of the bus stop.\n",
        "- PhotoF: link to a front photo of the bus stop\n",
        "- PhotoS: link to a side photo of the bus stop\n",
        "\n",
        "- 'geometry' listing the type of geometry, in this case POINT. And two numbers - the coordinates of the point.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TiLShLTdePtk",
        "outputId": "3e9d8477-3f5c-4e74-fe77-1f62d988c085"
      },
      "outputs": [],
      "source": [
        "# let's have a look at the Leeds geopandas dataframe\n",
        "leeds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yQT__kseQ4T"
      },
      "source": [
        "### Leeds\n",
        "LSOA level polygon file for Leeds with 2021 census data bout travel to work distance and transport mode- downloaded from [geoportal](https://geoportal.statistics.gov.uk/datasets/ons::lower-layer-super-output-areas-december-2021-boundaries-ew-bfc-v10-2/about): \n",
        "- Notice this time the 'geometry' column has more than two numbers and 'POLYGON()' rather than 'POINT()'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP-Zn76_RmOp"
      },
      "source": [
        "## Simple spatial data visualisation\n",
        "### Point data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "1vDUkDkRRmOp",
        "outputId": "2d5df78c-a696-44c4-bf52-f5835bad85d1"
      },
      "outputs": [],
      "source": [
        "# Plot the bus stop data\n",
        "\n",
        "# define the plot size and nummber of subplots (1 i.e. 1 plot)\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "# plot the  bus stop, specifying the subplot axis\n",
        "bus_stops.plot(ax=ax)\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3YjUFBIRmOq"
      },
      "source": [
        "### Polygon data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "E1wkSUGmRmOq",
        "outputId": "eb9a67cd-e87e-4b46-baeb-a41d983ca515"
      },
      "outputs": [],
      "source": [
        "# Plot the leeds data\n",
        "\n",
        "# define the plot size and nummber of subplots (1 i.e. 1 plot)\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "# plot the  leeds data, specifying the subplot axis\n",
        "leeds.plot(ax=ax)\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlfUs3-URmOr"
      },
      "source": [
        "<b>Note</b> the geometry column this time is made up of POLYGON data, made up of many coordiante points. <br>\n",
        "Let us have a closer look at the polygon geometry. We are going to look at the geometry of row 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "2ba_c_5WgBtI",
        "outputId": "b10fca9b-2609-407f-921c-925add1d5f8b"
      },
      "outputs": [],
      "source": [
        "# Lets look at index 3 (for me it is 'Leeds 009B') of the geometry column\n",
        "leeds.loc[3,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5soolSBPRmOr",
        "outputId": "7036502e-f582-46b2-aa90-0a50e0d276ba"
      },
      "outputs": [],
      "source": [
        "# Now let us look at the geometry column\n",
        "# Notice the shape is quite complex with lots of edges\n",
        "leeds.loc[3,'geometry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr7kmaYwRmOs",
        "outputId": "fcc0c544-05d5-45de-854b-1e51daacbf73"
      },
      "outputs": [],
      "source": [
        "# let us look at the list of coordiantes\n",
        "print(leeds.loc[3,'geometry'])\n",
        "# Each point is a corner of the LSOA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcoexfLERmOs"
      },
      "source": [
        "### geopandas.explore()\n",
        "\n",
        "<code>gpd.explore()</code> is a really useful function that generate an interactive leaflet map based on GeoDataFrame. It is particulalry useful for inital data exploration. the function creates:\n",
        "- a navigatable map\n",
        "- with 'zoom in and out' functionality\n",
        "- and hover over function displaying the variables in the GeoDataFrame\n",
        "\n",
        "The <code>.explore()</code> has many customisabel parameters, see the [package documentation](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JnjUjNPbRmOt",
        "outputId": "a29c410d-0791-451f-803b-cb45f4e2f919"
      },
      "outputs": [],
      "source": [
        "bus_stops.explore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "deFDOQsjRmOt",
        "outputId": "7756baa1-8120-4ef3-e700-d44b5afeb8ab"
      },
      "outputs": [],
      "source": [
        "leeds.explore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVXQ0vDXRmOt"
      },
      "source": [
        "## Coordinate Reference Systems (CRS)\n",
        "Before we map multiple layers we need to check they have the same Coordinate Reference System (CRS). Using the <code>.crs</code> function.\n",
        "\n",
        "This displays useful information about the projection used, which areas it can be used in etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfwmBm8LgzRj",
        "outputId": "544927df-7359-41e1-cd50-a55f0d4a3f5f"
      },
      "outputs": [],
      "source": [
        "leeds.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIHvLCTsRmOu"
      },
      "source": [
        "Look at what happens when we change the projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pN5Q7i0RmOu"
      },
      "outputs": [],
      "source": [
        "# NAD83 Canadian Spatial Reference System: Large and medium scale topographic mapping and engineering survey.\n",
        "leeds_new_proj= leeds.to_crs(epsg=2953)\n",
        "\n",
        "# EPSG:3851 New Zealand Geodetic Datum 2000: Spatial referencing and conformal mapping on the NZ continental shelf.\n",
        "leeds_new_proj2= leeds.to_crs(epsg=3851)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9InctyEphXLm",
        "outputId": "aff4168c-7ea6-404e-c06d-3c72da87bba4"
      },
      "outputs": [],
      "source": [
        "leeds_new_proj.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "Xgv-XxCHRmOu",
        "outputId": "d4ed6043-1d7e-482d-e34d-563d1f59db7d"
      },
      "outputs": [],
      "source": [
        "# plot the two diifferent new projections alongside the original projection\n",
        "f, ax = plt.subplots(1,3, figsize=(30, 20))\n",
        "leeds.plot(ax=ax[0])\n",
        "leeds_new_proj.plot(ax=ax[1])\n",
        "leeds_new_proj2.plot(ax=ax[2])\n",
        "plt.show()\n",
        "# Note the different scales on the axis and orrientation of the LSOAs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUWyklTfRmOv"
      },
      "source": [
        "## Layering maps\n",
        "Much like other mapping software it is possible to layer maps in Python. We will plot the cities on top of the countires dataset.\n",
        "\n",
        "We need to check the CRS of both datasets is the same so we can accurately plot the layers on top of each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTMnDh5tRmOv",
        "outputId": "4bfe04f6-9403-4c43-a276-4ee81ebd3b03"
      },
      "outputs": [],
      "source": [
        "# Check the CRS are the same\n",
        "print(leeds.crs, bus_stops.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8CDR4xTRmOv"
      },
      "source": [
        "## Plot the bus stops and LSOAs together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Druxo5gnRmOv",
        "outputId": "67c3c9cf-01f5-46b0-d1e2-55e06fc5781b"
      },
      "outputs": [],
      "source": [
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax)\n",
        "\n",
        "# plot the bus stops on the basemap axis, colour the bus stops red\n",
        "bus_stops.plot(ax=base,color='red')\n",
        "\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz6jzP4Hhslk"
      },
      "source": [
        "As we can see we are able to plot the bus stop data (for the whole of West Yorkshire) onto the Leeds Map."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTwABNZdRmOw"
      },
      "source": [
        "## Choropleth Mapping\n",
        "Choropleth maps are maps where the polygons are coloured differenet shades or colours based on a value. E.g. Number of people commuting by bus per LSOA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwOL9pjZRmOw"
      },
      "outputs": [],
      "source": [
        "# Define plot size\n",
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "# Plot the LSOAs, specifying to plot the 'Bus, minibus or coach' column\n",
        "# Add legend (legend =True)\n",
        "leeds.plot(ax=ax, column ='Bus, minibus or coach', legend=True)\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYiNSA5vRmOw"
      },
      "source": [
        "<font color= 'orchid'> <b>Code your own choropleth map for 'Works mainly from home'<b></font><br>\n",
        "    Answer at the end of the workbook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyINOKcTRmOx"
      },
      "outputs": [],
      "source": [
        "# code your choropleth map here!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgL6Wm0XRmOx"
      },
      "source": [
        "### Plotting Categorical variables\n",
        "First let's generate a categorical variable. We might be interested in the most common type of public trasnport used in each LSOA.\n",
        "\n",
        "Have a look at the <code>.idxmax()</code> documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
        "\n",
        "- what are we doing here?\n",
        "- what does <code>axis=1</code> do in the function?\n",
        "\n",
        "\n",
        "Comment the code below to demonstrate you know what it is doing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "leeds['most_common_public_transit']=leeds[['Underground, metro, light rail, tram',\n",
        "       'Train', 'Bus, minibus or coach', 'Taxi',\n",
        "       'Motorcycle, scooter or moped', 'Bicycle', 'On foot']].idxmax(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is possible to create choropleth maps with categorical variables (e.g. most_common_public_transit). To do this we specify <code> categorical=True,</code> withn the <code>plot()</code> function.<br> \n",
        "\n",
        "Note the legend of the map is now separate colours and not a continuous colour bar\n",
        "\n",
        "<font color ='orchid'> <b> Run the code below to plot a categorical chloropleth </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Let's improve this visualisation a bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "# plot the 'most_common_public_transit'column\n",
        "## use the tab20_r palette, tabe20\n",
        "leeds.plot(ax=ax, column ='most_common_public_transit', categorical=True, cmap='Set2', legend=True)\n",
        "# get the axis for the legend\n",
        "leg = ax.get_legend()\n",
        "# move the legend axis to the bottom left corner. \n",
        "leg.set_bbox_to_anchor((0.3, 0.2))\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "# set title\n",
        "ax.set_title('Most common public transport used to commute (LSOA)')\n",
        "# show plot\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<code>leg.set_bbox_to_anchor((0.3, 0.2))</code> Try editing the coordinates in the <code>set_bbox_to_anchor()</code> function. See where the legend moves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "leeds['WD24NM'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQ0gTtARmOy"
      },
      "source": [
        "## Subsetting spatial data\n",
        "We can also work with and plot just a subset of the spatial data. For example we might only be interested in the Ward of 'Headingley & Hyde Park' in Leeds. In which case we can use the <code>.loc[]</code> fucntion to locate all rows (LSOAs) where the ward is 'Headingley & Hyde Park'. Just like we would normally do in a non-spatial pandas dataframe.<br>\n",
        "\n",
        "<font color ='orchid'> <b>Run the code below </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvt4pTQxRmOy",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# locate LSOAs (rows) in the Ward ('WD24NM') of 'Headingley & Hyde Park'\n",
        "hyde_park = leeds.loc[leeds['WD24NM']== 'Headingley & Hyde Park',:]\n",
        "# view the newly created hyde park dataframe\n",
        "hyde_park"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy03Xo4pRmOy"
      },
      "source": [
        "It is now possible to plot just Hyde Park and Headingley. We can also put maps side by side to compare them. Here we are going to number of popele commuting by bike versus on Food for each LSOA.<br>\n",
        "\n",
        "<font color = 'orchid'> <b> Run the code below,</b> make sure you understand what each line does (there is a lot going on)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLV_bp9MRmOy"
      },
      "outputs": [],
      "source": [
        "# create a figure with two subplots (maps)\n",
        "f,ax = plt.subplots(1,2, figsize=(12,6))\n",
        "\n",
        "# plot population estimate in subplot 1\n",
        "hyde_park.plot(ax=ax[0], column ='On foot', legend=True)\n",
        "\n",
        "# plot gdp estimate in subplot 2\n",
        "hyde_park.plot(ax=ax[1], column ='Bicycle', legend=True)\n",
        "\n",
        "# give subplot 1 an informative title\n",
        "ax[0].set_title('On foot')\n",
        "\n",
        "# give subplot 2 an informative title\n",
        "ax[1].set_title('Bicycle')\n",
        "\n",
        "# make axis invisible for subplot 1\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "# make axis invisible for subplot 1\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "# show figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyde_park[['On foot','Bicycle']].max().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Lety's improve the plots further\n",
        "\n",
        "# create a figure with two subplots (maps)\n",
        "f,ax = plt.subplots(1,2, figsize=(12,6))\n",
        "\n",
        "\n",
        "# Normalize data with a set center.\n",
        "## https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.colors.TwoSlopeNorm.html?highlight=twoslopenorm#matplotlib.colors.TwoSlopeNorm\n",
        "# define the minimum and maximum limits of the cbar\n",
        "\n",
        "# minimum = 0 (as count data)\n",
        "vmin =0\n",
        "# calculate the maximum value across both columns \n",
        "vmax = hyde_park[['On foot','Bicycle']].max().max()\n",
        "# use the maximum bicycle value (the smaller of the two counts) as the midpoint of the colorbar\n",
        "vcenter=hyde_park['Bicycle'].max()\n",
        "\n",
        "# normalise the data with a center\n",
        "from matplotlib import colors\n",
        "divnorm=colors.TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
        "\n",
        "# plot population estimate in subplot 1, \n",
        "# shrink legend and normalise cbar\n",
        "hyde_park.plot(ax=ax[0], column ='On foot', legend=True, legend_kwds={'shrink': 0.4}, norm=divnorm)\n",
        "\n",
        "# plot gdp estimate in subplot 2\n",
        "# shrink legend and normalise cbar\n",
        "hyde_park.plot(ax=ax[1], column ='Bicycle', legend=True, legend_kwds={'shrink': 0.4}, norm=divnorm)\n",
        "\n",
        "# give subplot 1 an informative title\n",
        "ax[0].set_title('Number of working population commuting on foot')\n",
        "\n",
        "# give subplot 2 an informative title\n",
        "ax[1].set_title('Number of working population commuting by bicycle')\n",
        "\n",
        "# make axis invisible for subplot 1\n",
        "ax[0].set_axis_off()\n",
        "\n",
        "# make axis invisible for subplot 1\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "# show figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-8XUnhaRmOy"
      },
      "source": [
        "## Subplots and axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gOlqRpURmOz"
      },
      "source": [
        "A quick note on the subplot and ax indexing. It can be a little tricky getting your head arround the indexing used when creating subplots.\n",
        "To create mulitple subplots you use the code below, specifying firstly the number of rows then the number of columns. <br>\n",
        "<code>.subplots([number of rows], [number of columns])</code>\n",
        "\n",
        "When you are then specifyng each individual plot, you need to specify the axes of the plot, using the code <code> ax=ax[]</code>. The indexing for the axes starts at 0. I.e. the first row is 'row 0' and the first column, 'column 0'. This is illustrated below.\n",
        "\n",
        "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_diagram.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE5rFIAURmOz"
      },
      "source": [
        "For a set of subplots with just one row you only need to specify the column in the <code>ax=ax[]</code> function. <br>\n",
        "I.e. <code>ax=ax[column number]</code> <br>\n",
        "\n",
        "I.e.<code> plt.subplot(1,2) <br>\n",
        "dataframe.plot(ax=ax[0], ...\n",
        "dataframe.plot(ax=ax[1], ... </code>\n",
        "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8qPeaFfRmOz"
      },
      "source": [
        "Simialrly for a set of subplots with just one column you only need to specify the row in the <code>ax=ax[]</code> function. <br>\n",
        "<code> plt.subplot(2,1) <br>\n",
        "dataframe.plot(ax=ax[0], ...\n",
        "dataframe.plot(ax=ax[1], ... </code>\n",
        "</code>\n",
        "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_3.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTs1qUlKRmOz"
      },
      "source": [
        "For a set of subplots with just multiple rows and columns you only need to specify both in the <code>ax=ax[,]</code> funciton.(row first then column)<br>\n",
        "<code>plt.subplot(2,3)<br>\n",
        "dataframe.plot(ax=ax[0,0], ...\n",
        "dataframe.plot(ax=ax[0,1], ...\n",
        "dataframe.plot(ax=ax[0,2], ...\n",
        "dataframe.plot(ax=ax[1,0], ...\n",
        "dataframe.plot(ax=ax[1,1], ...\n",
        "dataframe.plot(ax=ax[1,2], ...</code>\n",
        "![](https://github.com/FrancescaPontin/GEOG5990M/blob/main/notebooks/screenshots/axes_4.png?raw=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Wbw7YLRmOz"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "## Extra task: Using USA data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6c76UpURmO0"
      },
      "source": [
        "### The data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3puWztORmO0"
      },
      "outputs": [],
      "source": [
        "usa_cities = gpd.read_file(gplt.datasets.get_path('usa_cities'))\n",
        "contiguous_usa = gpd.read_file(gplt.datasets.get_path('contiguous_usa'))\n",
        "\n",
        "# remove cities in sates not in the contiguous USA (not connected directly to the mainland), for ease of plotting\n",
        "continental_usa_cities = usa_cities.loc[(usa_cities['STATE'] !=\"HI\") & (usa_cities['STATE'] !=\"AK\" ) & (usa_cities['STATE'] !=\"PR\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aOJfLKW0RmO0",
        "outputId": "096c89f3-060d-4320-da98-885b614db51e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "continental_usa_cities.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSHk0wPRmO0"
      },
      "outputs": [],
      "source": [
        "continental_usa_cities.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOdkGXJgRmO0"
      },
      "outputs": [],
      "source": [
        "contiguous_usa.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8eWuawuRmO1"
      },
      "outputs": [],
      "source": [
        "contiguous_usa.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWaUHSZcRmO1"
      },
      "source": [
        "### Tasks:\n",
        "- check the CRS of both geo data frames\n",
        "- produce a layered map of cities and states\n",
        "- Produce a choropleth map of 2010 popualation\n",
        "- produce a choropleth map of elevation\n",
        "- Colour city by state\n",
        "- subset the data to plot a single state e.g. Washington"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjry-T8RmO1"
      },
      "source": [
        "# Exercise: Manipulating spatial data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4YlDUoGRmO1"
      },
      "source": [
        "## Geometric Manipulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For the sake of this exercise we are going to change the projection of the data\n",
        "bus_stops_p1 =bus_stops.to_crs('epsg:4326')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare CRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bus_stops.crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice in the British National Grid projection(EPSG:27700) the axis information indicates the units used are metres: <br>\n",
        "\n",
        "<code>Axis Info [cartesian]:</code><br>\n",
        "<code> - E[east]: Easting (metre)</code><br>\n",
        "<code> - N[north]: Northing (metre)</code>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bus_stops_p1.crs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice in the WGS 84 (World Geodetic System) projection(EPSG:4326) the axis information indicates the units used are degrees: <br>\n",
        "\n",
        "<code>Axis Info [ellipsoidal]:</code><br>\n",
        "<code>- Lat[north]: Geodetic latitude (degree)</code><br>\n",
        "<code>- Lon[east]: Geodetic longitude (degree)</code><br>\n",
        "\n",
        "\n",
        "Projection therefore matters when we come to do spatial analysis with our data (just like in every other GIS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otbjaLImRmO1"
      },
      "source": [
        "### Buffers\n",
        "\n",
        "A buffer in geographic information system (GIS) is a zone around a map feature measured in units of distance or time.\n",
        "\n",
        "In Python we specify the buffer size: the radius of the buffer (in this case size is measured in meters as the projection is EPSG:27700).\n",
        "\n",
        "E.g.:\n",
        "\n",
        "<code> dataframe.buffer(distance =800) </code> distance = 800 meters.\n",
        "\n",
        "800 meters is often used to represent a 5 minute walk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plot 800m meter arround bus stops\n",
        "\n",
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "bus_stops.buffer(distance=800).plot(ax=ax)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the projection was ESG:4326 the buffer would be calcualted using degress- see what happens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdLCQw1KRmO2"
      },
      "outputs": [],
      "source": [
        "bus_stops_p1.buffer(distance=10).explore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the code without plotting- notice we generate an array of geometries \n",
        "bus_stops.buffer(distance=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can check the data type- a geopandas array\n",
        "bus_stops.buffer(distance=800).dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-G5peORmO2"
      },
      "source": [
        "In order to keep information about the area begin buffered in the newly created buffer geo-data-frame it is useful to copy the original data you want to conduct the geometric maipulation on, and name it something else e.g. dataframe_buffer.\n",
        "\n",
        "Then replace the geometry column in the copied data with the calculated buffer geometry.\n",
        "\n",
        "E.g.\n",
        "<code> dataframe_buffer = dataframe.copy() </code>\n",
        "\n",
        "<code> dataframe_buffer['geometry'] = dataframe.buffer(distance)</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLpMiUjERmO3"
      },
      "outputs": [],
      "source": [
        "# copy the bus stops dataframe\n",
        "bus_stops_buffer = bus_stops.copy()\n",
        "\n",
        "# apply the function (replacing the geometry column with the buffer geometry)\n",
        "bus_stops_buffer['geometry'] = bus_stops.buffer(distance=800)\n",
        "\n",
        "bus_stops_buffer.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX4zms58RmO3"
      },
      "source": [
        "Note because we copied the bus_stops data frame above the bus_stops_buffer data frame still contains the name of the bus stop and other infomration e.g. average number of buses in the morning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4s0u79rRmO3"
      },
      "source": [
        "We can add the bus_stop_buffer layer to the map along with the bus_stop and leeds layers.\n",
        "\n",
        "<font color = 'orchid'> <b> Run the code below, read the comments to understand what each line of code is doing  </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvsV2pK5RmO3",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# plot the bus stop buffers on the basemap axis, colour buffers blue\n",
        "bus_stops_buffer.plot(ax=base,color='blue', alpha=0.2)\n",
        "\n",
        "# plot the bus stops on the basemap axis, colour the bus stops red\n",
        "bus_stops.plot(ax=base,color='red', markersize=1)\n",
        "\n",
        "# shw the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrLkvSSYRmO4"
      },
      "source": [
        "### Centroids\n",
        "\n",
        "Put simply the centroid is the center most point of a polygon (there are different debated methods of calculating centroids, but unless you are using centroids for a specific purpose the method should not matter too much).\n",
        "\n",
        "#### Why calculate centroids?\n",
        "\n",
        "Lots of geometric manipulations and analysis use centroids. For example you might use centroids to as a proxy to measure the distance between two polygons.\n",
        "\n",
        "\n",
        "<font color = 'orchid'> <b>Use the code </b> <code> dataframe.centroid </code> <b>to find the LSOA centroids (run the next 3 cells of code for the worked example below) </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr8vLB7kRmO4"
      },
      "outputs": [],
      "source": [
        "# copy the leeds dataframe\n",
        "leeds_centroid = leeds.copy()\n",
        "\n",
        "# calcualte the centorid\n",
        "# and replace the leeds geometry (polygon) with the centroid geometry (point)\n",
        "leeds_centroid['geometry'] = leeds.centroid\n",
        "\n",
        "# check - geometry should contain point data\n",
        "leeds_centroid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65q5jkQwRmO5"
      },
      "outputs": [],
      "source": [
        "# plot to check it looks as expected\n",
        "leeds_centroid.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PSx68-iRmO5"
      },
      "outputs": [],
      "source": [
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# plot the lsoa centroids on the basemap axis, colour the centroids purple\n",
        "leeds_centroid.plot(ax=base,color='purple')\n",
        "\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kUAxJ0-RmO5"
      },
      "source": [
        "We can also change marker size and colour of plotted points to reflect the data they represent (as we did with the chloropleth maps for polygon data).\n",
        "\n",
        "<font color = 'orchid'> <b>Run the code below</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmRqFMlLRmO5"
      },
      "outputs": [],
      "source": [
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# plot the lsoa centroids on the basemap axis, colour and size the centroids based opn number of people commuting by bus\n",
        "leeds_centroid.plot(ax=base, markersize='Bus, minibus or coach', column='Bus, minibus or coach',  legend=True)\n",
        "\n",
        "# make axis invisible\n",
        "ax.set_axis_off()\n",
        "\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can improve this visualsiaiton further by scaling the marker size, adjusting the legend extent and adding a title\n",
        "\n",
        "<font color = 'orchid'> <b>Run and read the code below,check you understand what is happening on each line</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# plot the lsoa centroids on the basemap axis, colour and size the centroids based opn number of people commuting by bus\n",
        "# scale the marker size to fit better and make make semi-opaque to see overlap in dense areas\n",
        "# start colorbar legend at 0 as count data\n",
        "leeds_centroid.plot(ax=base, markersize=leeds_centroid['Bus, minibus or coach']/4, column='Bus, minibus or coach', alpha=0.8, legend=True, vmin=0)\n",
        "\n",
        "# make axis invisible\n",
        "ax.set_axis_off()\n",
        "\n",
        "# add title, increase fontsize\n",
        "ax.set_title('Number of people commuting by bus in Leeds by LSOA', fontsize =14)\n",
        "\n",
        "# show the map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97fn-X6YRmO6"
      },
      "source": [
        "### Convex hull polygons\n",
        "\n",
        "A convex hull is the smallest polygon that you can draw around a collection of points/a polygon.\n",
        "\n",
        "<font color = 'orchid'> <b>Run the code below to create convex hull polygons (using the code </b><code> dataframe.convex_hull</code><b> around the lsoas in Leeds </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YlT88D5RmO6"
      },
      "outputs": [],
      "source": [
        "leeds_convex_hull = leeds.copy()\n",
        "\n",
        "# replace the geometry column with the calculated convexhull polygon geometries \n",
        "leeds_convex_hull['geometry'] = leeds.convex_hull\n",
        "\n",
        "# plot one subplot (1 map), with dimensions 16 X 8\n",
        "f, ax = plt.subplots(1, figsize=(16, 8))\n",
        "\n",
        "# define the basemap plot it on the sublot axis\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# plot the africa convex hull polygons\n",
        "# .boundary alows us to just plot the polygon outline\n",
        "leeds_convex_hull.boundary.plot(ax=base)\n",
        "\n",
        "# make axis invisible\n",
        "ax.set_axis_off()\n",
        "\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_cc0h-lRmO6"
      },
      "source": [
        "## Spatially aggregating data\n",
        "Often our data will not be at the same spatial scale so we may need to aggreaget areas of data together to get them to the same spatial scale. Or we may only be interested in larger spatial trends. Therefore we need to convert our smaller area data to larger area data. In geopandas we can easily so this using the <code>dissolve</code> function.\n",
        "In this example we are going to aggregate LSOAs up to ward (WD24NM) level. <br>\n",
        "Think of dissolve as removing all the internal LSOA boarders within the ward to leave just the ward outline.<br>\n",
        "The data for the ward also gets aggregated, below we have agregated all the numeric data <br>\n",
        "<font color='orchid'> <b> Run the code below </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZwQ9ULsRmO7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# specify which columns from the leeds dataframe we are going to aggreagate: \n",
        "# #this should include the column we are going to aggregate the data by (i.e. WD24NM), the geometry column and any other columns we want to aggregate\n",
        "# use the WD24NM column to inform the dissolve, \n",
        "# in this case sum is a suitable aggregation to get the total within the wards, we could also use 'mean' to get the avergae within the wards\n",
        "leeds_wards = leeds[['WD24NM','Total_distance_to_work', 'Less than 10km',\n",
        "       '10km to less than 30km', '30km and over', 'Works mainly from home',\n",
        "       'Not in employment or works mainly offshore, in no fixed place or outside the UK',\n",
        "       'Work mainly at or from home', 'Underground, metro, light rail, tram',\n",
        "       'Train', 'Bus, minibus or coach', 'Taxi',\n",
        "       'Motorcycle, scooter or moped', 'Driving a car or van',\n",
        "       'Passenger in a car or van', 'Bicycle', 'On foot',\n",
        "       'Other method of travel to work',\n",
        "       'Not in employment or aged 15 years and under','geometry']].dissolve(by='WD24NM', aggfunc='sum').reset_index()\n",
        "\n",
        "# view the new leeds_wards dataframe\n",
        "leeds_wards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the new leeds_wards df\n",
        "\n",
        "leeds_wards.explore(column ='Bus, minibus or coach', vmin=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYKzIEIkRmO7"
      },
      "source": [
        "Think carefully about how you want to aggregate the columns, we can also assign an aggfunction to each column (as we did with <code>.agg()</code> when looking at the bike share data).\n",
        "\n",
        "E.g.\n",
        "<code>, aggfunc={'r_rank':'mean','r_exp':'max'})</code>\n",
        "\n",
        "There is no quick way to assign multiple columns the same function so with a large dataset you might want to consider which columns you include in the aggregated spatial data frame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Replicate and edit the code above to aggregate the LSOA data to plot mean number of people commuting by bike per ward \n",
        "(Answer at the end)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGJIOw7RmO8"
      },
      "source": [
        "## Joining a non-spatial dataset to a spatial dataset\n",
        "\n",
        "We are going to read in some data about the resident popualtion of lsoas across the UK and join it to the Leeds data frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wChOZuJLRmO8"
      },
      "source": [
        "<font color ='orchid'><b> Run the code below to read in a csv of lsoa level resident population data </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in residential popualtion data from 2021 census\n",
        "lsoa_resident_pop =pd.read_csv('https://github.com/FrancescaPontin/GEOG5990M/raw/refs/heads/main/data/week_6_7/lsoa_resident_pop.csv')\n",
        "# use loc to subset data to only contain data for Leeds\n",
        "leeds_resident_pop =lsoa_resident_pop.loc[lsoa_resident_pop['geography'].str.contains('Leeds'),:]\n",
        "# have a quick look at the dataframe\n",
        "leeds_resident_pop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Check both datasets have the same number of rows:', leeds_resident_pop.shape[0], leeds.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "leeds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLI78lVRmO9"
      },
      "source": [
        "The 'LSOA21CD' column in the leeds dataframe matches that of the 'geography code' column in the leeds_resident_pop data frame. As they are formatted in exactly the same way and each row is a unique LSOA, the geography code/ LSOA21CD is an unqiue identifier common to both data frames. Therefore, we will use this column to join our datasets. <br>\n",
        "The code we will use is <code>pd.merge()</code>. We need to specify a few parameters within the function:<br>\n",
        "\n",
        "- Firstly we specify which dataframes we want to join (in the order we want to join them).<br>\n",
        "<code> pd.merge(leeds, leeds_resident_pop... </code> <br>\n",
        "\n",
        "\n",
        "- Secondly we need to specify the column in each dataframe, leeds is on the left so we specify left_on='LSOA21CD': as we are using the 'LSOA21CD' column from the leeds dataframe. And the leeds_resident_pop dataframe is on the right so we specify right_on='geography code' as we are using the 'geography code' column for our join.<br>\n",
        "<code> pd.merge(leeds, leeds_resident_pop, left_on='LSOA21CD', right_on='geography code' ... </code> <br>\n",
        "\n",
        "\n",
        "- Finally we need to specify how the tables are joined. This is based on [SQL join fomats](http://www.complexsql.com/sql-joins-2/). In this case we are using a left join (we keep all the data in the left dataframe and just add the columns form the right dataframe on the end).\n",
        "<code> pd.merge(leeds, leeds_resident_pop, left_on='LSOA21CD', right_on='geography code', how='left') </code> <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsDJwNp6RmO9"
      },
      "outputs": [],
      "source": [
        "leeds_pop = pd.merge(leeds, leeds_resident_pop, left_on='LSOA21CD', right_on='geography code', how='left')\n",
        "leeds_pop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if any of the rows in the newly joined columns are NA, if so this might suggest that the join has not worked as expected \n",
        "leeds_pop['Residence type: Total; measures: Value'].isna().any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV4Q7Pk5RmO9"
      },
      "source": [
        "Now we will visualise our newly joined data by plotting the total resident population in each lsoa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK2m8a3GRmO9"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "leeds_pop.plot(column='Residence type: Total; measures: Value',legend=True,ax=ax)\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jze37momRmO9"
      },
      "source": [
        "Because there is such a large variation in population in the above map with a continuous scale can be difficult to distinguish between differences in smaller population numbers. To make a more informative plot we can use <code> scheme = ' '</code>\n",
        "And use <code> ['equal_interval', 'quantiles', 'fisher_jenks', 'fisher_jenks_sampled']</code> to define how the choropleth map is scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFPeOf1jRmO-"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "leeds_pop.plot(column='Residence type: Total; measures: Value',legend=True, cmap='summer',scheme='equal_interval', k=6, ax=ax)\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "# position legend\n",
        "ax.get_legend().set_bbox_to_anchor((.12, .4))\n",
        "# add title\n",
        "ax.set_title('Leeds total resident popualtion (LSOA)', fontsize=15)\n",
        "# add a North arrow (look at the docuemntaiton here: https://github.com/pmdscully/geo_northarrow)\n",
        "add_north_arrow(ax=ax, scale=.75, xlim_pos=0.1, ylim_pos=.85, color='#000', text_scaler=2, text_yT=-1.25)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DeSG6kIRmO-"
      },
      "source": [
        "<font color='orchid'><b> Write your own code to map 'Residence type: Lives in a communal establishment; measures: Value'</font> <br>\n",
        "Answer at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM-yPFs0RmO-"
      },
      "outputs": [],
      "source": [
        "# plot here!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tyYdDYiRmO-"
      },
      "source": [
        "## Spatially Joining Data\n",
        "\n",
        "It is also possible to join data based on their spatial relationship to each other using <code>.sjoin()</code>\n",
        "For example we ight want to know the lsoa each bus stop is in.\n",
        "\n",
        "\n",
        "Like with <code>pd.merge()</code> there are parameters we need to specify when using <code>gpd.sjoin()</code>\n",
        "\n",
        "- Again firstly we specify which dataframes we want to join (in the order we want to join them).<br>\n",
        "<code>gpd.sjoin(bus_stops, leeds, ... </code> <br>\n",
        "\n",
        "\n",
        "- Secondly we need to specify how the tables are joined. (Again based on [SQL join fomats](http://www.complexsql.com/sql-joins-2/)). In this case we are using an inner join\n",
        "<code> gpd.sjoin(bus_stops, leeds, how=\"inner\",... </code> <br>\n",
        "\n",
        "- Finally, we need to specify the type of spatial join using 'op'. From the [Geopandas documentation](http://geopandas.org/mergingdata.html) <br>\n",
        "<i>The `op argument specifies how geopandas decides whether or not to join the attributes of one object to another. There are three different join options as follows:\n",
        "    - <b>intersects:</b> The attributes will be joined if the boundary and interior of the object intersect in any way with the boundary and/or interior of the other object.\n",
        "    - <b>within:</b> The attributes will be joined if the object’s boundary and interior intersect only with the interior of the other object (not its boundary or exterior).\n",
        "    - <b>contains:</b> The attributes will be joined if the object’s interior contains the boundary and interior of the other object and their boundaries do not touch at all. </i> <br>\n",
        "    \n",
        "<font color = 'orchid'><b> Run the code below to spatially join the data </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hbre_x2RmO-"
      },
      "outputs": [],
      "source": [
        "bus_stops_leeds = gpd.sjoin(bus_stops, leeds, how=\"inner\", op='intersects')\n",
        "# looka t the data: notice that we now have the LSOA level info for each bus stop \n",
        "bus_stops_leeds .head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note when mapped we now just have bus stops within Leeds, not the whole of West Yorkshire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0SOY9SaRmO_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# let us plot the bus stops now coloured by the the number of people commuting by bus in that LSOA\n",
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "\n",
        "# map the leeds LSOAs (basemap)\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "# plot the bus stops and colour them based on n of people commuting by bus in the LSOA in which the bus stop is\n",
        "bus_stops_leeds.plot(ax=base,  column ='Bus, minibus or coach', cmap='viridis',markersize=2, vmin=0,legend=True)\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dygUoWzXRmO_"
      },
      "source": [
        "## Overlay - creating spatial layers from the intersections, unions, and differences between map\n",
        "I have included this for reference with a worked example, to show you how we can look at where spatial data overlaps. Full description an a list of the overlay operations can be found here: https://geopandas.org/set_operations.html\n",
        "Have a read and explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApvDcvF3RmO_"
      },
      "outputs": [],
      "source": [
        "# get the intersection between the 5 minute walk of a bus stop buffer and lsoas to see how much of the LSOA is accessible by bus\n",
        "lsoas_in_buff =gpd.overlay(bus_stops_buffer , leeds, how='intersection')\n",
        "# look at the data\n",
        "lsoas_in_buff "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdgvGwQqRmPA"
      },
      "outputs": [],
      "source": [
        "# plot ther results \n",
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "\n",
        "# lsoa base map\n",
        "base = leeds.plot(ax=ax,color='grey')\n",
        "# plot the intersection of bus stop buffer and lsoas \n",
        "lsoas_in_buff .plot(ax=base, alpha=0.8)\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8EvhGrRmPA",
        "scrolled": true
      },
      "source": [
        "### Kernel density map\n",
        "\n",
        "Much like the kernel density plots we produced in day 1 this produces a kernel density estimate of spatial point data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw8EvhGrRmPA",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## Seaborn example\n",
        "\n",
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "\n",
        "# map the leeds (basemap)\n",
        "base = leeds.plot(ax=ax, color='grey')\n",
        "\n",
        "# map the kernel density estimate of bus stops\n",
        "sns.kdeplot(bus_stops_leeds, x='x', y='y', color='Red', fill=True,ax=base, alpha=0.8)\n",
        "\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZafSL4dRmPB"
      },
      "source": [
        "### Adding base maps\n",
        "Base maps provide the reader with context for a map. At a smaller scale than we are currently using the basemap may show road networks or point of interest.\n",
        "\n",
        "We are going to use contextily to add the background map to the geographic data using the <code>.basemap()</code> function.\n",
        "\n",
        "#### Aligning the CRS\n",
        "But first we need to convert the CRS of the data we want to plot to the Web Mercator projection (epsg=3857). So the base maps and geographic data we are plotting align.\n",
        "\n",
        "Unless the data file I want to plot is particularly big I tend to save the data with the Web Mercator projection as a new geodataframe to avoid confusion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkuxa9aMRmPB"
      },
      "outputs": [],
      "source": [
        "leeds.crs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e03f25ewRmPB"
      },
      "outputs": [],
      "source": [
        "# convert CRS to epsg=3857 Web Mercator\n",
        "leeds_WM = leeds.to_crs(epsg=3857)\n",
        "\n",
        "fig,ax = plt.subplots(1, figsize=(10,10))\n",
        "\n",
        "# plot the Leeds data as usual\n",
        "leeds_WM.plot(column='Works mainly from home',ax=ax,alpha=0.5)\n",
        "\n",
        "# add ctx basemap to ax\n",
        "ctx.add_basemap(ax, crs=leeds_WM.crs)\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRlIAi3wRmPB"
      },
      "source": [
        "#### Different base maps.\n",
        "By default ctx.add_basemap() uses the Stamen Terrain style.\n",
        "\n",
        "To see the available different base maps we can get the provider keys:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dl-QgG-RmPB"
      },
      "source": [
        "List of contextily providers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuGK5CXPRmPC"
      },
      "outputs": [],
      "source": [
        "ctx.providers.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmK4WdgRmPC"
      },
      "source": [
        "Each will have their own options, accessed by the code: <code> ctx.providers.<text color='red'>provider_from_above</font>.keys()</code>\n",
        "\n",
        "E.g. <code> ctx.providers.CartoDB.keys()</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypA1tvbRRmPC"
      },
      "outputs": [],
      "source": [
        "ctx.providers.CartoDB.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubcZ_yUFRmPC"
      },
      "source": [
        "We can then use the provider and porvider options to choose our base map e.g. <code>OpenStreetMap.Voyager</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttpsV2MbRmPC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "f,ax = plt.subplots(1, figsize=(16,16))\n",
        "\n",
        "# plot the Leeds data as usual\n",
        "leeds.plot(figsize=(10, 10), alpha=0.5,column='Works mainly from home',ax=ax)\n",
        "\n",
        "# add ctx basemap to ax, specifying the basemap provider and options\n",
        "ctx.add_basemap(ax,source=ctx.providers.CartoDB.Voyager, zoom=12, crs=leeds.crs)\n",
        "\n",
        "ax.set_axis_off()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(1, figsize=(16,16))\n",
        "\n",
        "# plot the Leeds data as usual\n",
        "leeds_WM.plot(figsize=(10, 10), alpha=0.5,column='Works mainly from home',ax=ax)\n",
        "\n",
        "# add ctx basemap to ax, specifying the basemap provider and options\n",
        "ctx.add_basemap(ax,source=ctx.providers.CartoDB.DarkMatter, zoom=12)\n",
        "\n",
        "ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWog6hHgRmPC"
      },
      "source": [
        "<font color='orchid'><b>  Play around with the providers and options to get different base maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m7UPmKhRmPC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBhP1JolRmPD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmcOBQWRRmPD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du7dFRUDRmPD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBJDKF4BRmPD"
      },
      "source": [
        "<h1> Exercise answers</h1>  <a class=\"tocSkip\">\n",
        "\n",
        "#### Plot Choropleth of number of people per LSOA working from home"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Plot Choropleth of number of people per LSOA working from home\n",
        "# Define plot size\n",
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "# Plot the LSOAs, specifying to plot the 'Works mainly from home' column\n",
        "# Add legend (legend =True)\n",
        "leeds.plot(ax=ax, column ='Works mainly from home', legend=True)\n",
        "# show the map\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Replicate and edit the code above to aggregate the LSOA data to plot mean number of people commuting by bike per ward "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify which columns from the leeds dataframe we are going to aggreagate: \n",
        "# calcualte mean bike commuting per ward\n",
        "leeds_wards_mean_bike = leeds[['WD24NM','Bus, minibus or coach', 'geometry']].dissolve(by='WD24NM', aggfunc='mean').reset_index()\n",
        "\n",
        "# view the new leeds_wards dataframe\n",
        "leeds_wards_mean_bike.explore('Bus, minibus or coach', vmin=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Write your own code to map 'Residence type: Lives in a communal establishment; measures: Value'\n",
        "\n",
        "Your map might look different depending on the scheme and number of breaks you used!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(1, figsize=(16,8))\n",
        "leeds_pop.plot(column='Residence type: Lives in a communal establishment; measures: Value',legend=True, cmap='summer',scheme='natural_breaks', k=5, ax=ax)\n",
        "# remove axis\n",
        "ax.set_axis_off()\n",
        "# position legend\n",
        "ax.get_legend().set_bbox_to_anchor((.12, .4))\n",
        "# add title\n",
        "ax.set_title('Leeds population living in a communal establishment (LSOA)', fontsize=15)\n",
        "# add a North arrow (look at the docuemntaiton here: https://github.com/pmdscully/geo_northarrow)\n",
        "add_north_arrow(ax=ax, scale=.75, xlim_pos=0.1, ylim_pos=.85, color='#000', text_scaler=2, text_yT=-1.25)\n",
        "plt.show();\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "376.4705810546875px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
>>>>>>> 5fccd06d3978f68803a672dfb88dc4cc2f8e7ef0
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
